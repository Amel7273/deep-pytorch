{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "958ae5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.1.1 희소표현(Sparse Representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d93e9e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "class2=pd.read_csv(\"../chap10/data/class2.csv\")\n",
    "\n",
    "from sklearn import preprocessing \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "onehot_encoder = preprocessing.OneHotEncoder()\n",
    "\n",
    "train_x = label_encoder.fit_transform(class2['class2'])\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af2eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.1.2 횟수기반 임베딩\n",
    "#Counter Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5298928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 13,\n",
       " 'is': 7,\n",
       " 'last': 8,\n",
       " 'chance': 2,\n",
       " 'and': 0,\n",
       " 'if': 6,\n",
       " 'you': 15,\n",
       " 'do': 3,\n",
       " 'not': 10,\n",
       " 'have': 5,\n",
       " 'will': 14,\n",
       " 'never': 9,\n",
       " 'get': 4,\n",
       " 'any': 1,\n",
       " 'one': 11,\n",
       " 'please': 12}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is last chance.',\n",
    "    'and if you do not have this chance.',\n",
    "    'you will never get any chance.',\n",
    "    'will you do get this one?',\n",
    "    'please, get this chance',\n",
    "]\n",
    "vect = CountVectorizer()\n",
    "vect.fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda3fe3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform(['you will never get any chance.']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b305aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last': 6,\n",
       " 'chance': 1,\n",
       " 'if': 5,\n",
       " 'you': 11,\n",
       " 'do': 2,\n",
       " 'not': 8,\n",
       " 'have': 4,\n",
       " 'will': 10,\n",
       " 'never': 7,\n",
       " 'get': 3,\n",
       " 'any': 0,\n",
       " 'one': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words=[\"and\", \"is\", \"please\", \"this\"]).fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d212c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fea52e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도를 위한 3 x 3 matrix를 만들었습니다.\n",
      "[[1.       0.224325 0.      ]\n",
      " [0.224325 1.       0.      ]\n",
      " [0.       0.       1.      ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "doc = ['I like machine learning', 'I love deep learning', 'I run everyday']\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=1)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(doc)\n",
    "doc_distance = (tfidf_matrix * tfidf_matrix.T)\n",
    "print ('유사도를 위한', str(doc_distance.get_shape()[0]), 'x', str(doc_distance.get_shape()[1]), 'matrix를 만들었습니다.')\n",
    "print(doc_distance.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52460393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.1.3 예측기반 임베딩\n",
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d68eed27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['once',\n",
       "  'upon',\n",
       "  'a',\n",
       "  'time',\n",
       "  'in',\n",
       "  'london',\n",
       "  ',',\n",
       "  'the',\n",
       "  'darlings',\n",
       "  'went',\n",
       "  'out',\n",
       "  'to',\n",
       "  'a',\n",
       "  'dinner',\n",
       "  'party',\n",
       "  'leaving',\n",
       "  'their',\n",
       "  'three',\n",
       "  'children',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'and',\n",
       "  'michael',\n",
       "  'at',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['after',\n",
       "  'wendy',\n",
       "  'had',\n",
       "  'tucked',\n",
       "  'her',\n",
       "  'younger',\n",
       "  'brothers',\n",
       "  'jhon',\n",
       "  'and',\n",
       "  'michael',\n",
       "  'to',\n",
       "  'bed',\n",
       "  ',',\n",
       "  'she',\n",
       "  'went',\n",
       "  'to',\n",
       "  'read',\n",
       "  'a',\n",
       "  'book',\n",
       "  '.'],\n",
       " ['she', 'heard', 'a', 'boy', 'sobbing', 'outside', 'her', 'window', '.'],\n",
       " ['he', 'was', 'flying', '.'],\n",
       " ['there', 'was', 'little', 'fairy', 'fluttering', 'around', 'him', '.'],\n",
       " ['wendy', 'opened', 'the', 'window', 'to', 'talk', 'to', 'him', '.'],\n",
       " ['“', 'hello', '!'],\n",
       " ['who', 'are', 'you', '?'],\n",
       " ['why', 'are', 'you', 'crying', '”', ',', 'wendy', 'asked', 'him', '.'],\n",
       " ['“', 'my', 'name', 'is', 'peter', 'pan', '.'],\n",
       " ['my',\n",
       "  'shadow',\n",
       "  'wouldn',\n",
       "  '’',\n",
       "  't',\n",
       "  'stock',\n",
       "  'to',\n",
       "  'me.',\n",
       "  '”',\n",
       "  ',',\n",
       "  'he',\n",
       "  'replied',\n",
       "  '.'],\n",
       " ['she', 'asked', 'him', 'to', 'come', 'in', '.'],\n",
       " ['peter', 'agreed', 'and', 'came', 'inside', 'the', 'room', '.'],\n",
       " ['wendy',\n",
       "  'took',\n",
       "  'his',\n",
       "  'shadow',\n",
       "  'and',\n",
       "  'sewed',\n",
       "  'it',\n",
       "  'to',\n",
       "  'his',\n",
       "  'shoe',\n",
       "  'tips',\n",
       "  '.'],\n",
       " ['now',\n",
       "  'his',\n",
       "  'shadow',\n",
       "  'followed',\n",
       "  'him',\n",
       "  'wherever',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'went',\n",
       "  '!'],\n",
       " ['he',\n",
       "  'was',\n",
       "  'delighted',\n",
       "  'and',\n",
       "  'asked',\n",
       "  'wendy',\n",
       "  '“',\n",
       "  'why',\n",
       "  'don',\n",
       "  '’',\n",
       "  't',\n",
       "  'you',\n",
       "  'come',\n",
       "  'with',\n",
       "  'me',\n",
       "  'to',\n",
       "  'my',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['the', 'neverland', '.'],\n",
       " ['i',\n",
       "  'lived',\n",
       "  'there',\n",
       "  'with',\n",
       "  'my',\n",
       "  'fairy',\n",
       "  'tinker',\n",
       "  'bell.',\n",
       "  '”',\n",
       "  'wendy',\n",
       "  '?'],\n",
       " ['“', 'oh', '!'],\n",
       " ['what', 'a', 'wonderful', 'idea', '!'],\n",
       " ['let', 'me', 'wake', 'up', 'john', 'and', 'micheal', 'too', '.'],\n",
       " ['could', 'you', 'teach', 'us', 'how', 'to', 'fly', '?', '”', '.'],\n",
       " ['“', 'yes', '!'],\n",
       " ['of', 'course', '!'],\n",
       " ['get',\n",
       "  'them',\n",
       "  'we',\n",
       "  'will',\n",
       "  'all',\n",
       "  'fly',\n",
       "  'together.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'replied',\n",
       "  'and',\n",
       "  'so',\n",
       "  'it',\n",
       "  'was',\n",
       "  '.'],\n",
       " ['five',\n",
       "  'little',\n",
       "  'figures',\n",
       "  'flew',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'window',\n",
       "  'of',\n",
       "  'the',\n",
       "  'darlings',\n",
       "  'and',\n",
       "  'headed',\n",
       "  'towards',\n",
       "  'neverland',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'they',\n",
       "  'flew',\n",
       "  'over',\n",
       "  'the',\n",
       "  'island',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'told',\n",
       "  'the',\n",
       "  'children',\n",
       "  'more',\n",
       "  'about',\n",
       "  'his',\n",
       "  'homeland',\n",
       "  '.'],\n",
       " ['“',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'who',\n",
       "  'get',\n",
       "  'lost',\n",
       "  'come',\n",
       "  'and',\n",
       "  'stay',\n",
       "  'with',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'and',\n",
       "  'me',\n",
       "  ',',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'told',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['the', 'indians', 'also', 'live', 'in', 'neverland', '.'],\n",
       " ['the',\n",
       "  'mermaids',\n",
       "  'live',\n",
       "  'in',\n",
       "  'the',\n",
       "  'lagoon',\n",
       "  'around',\n",
       "  'the',\n",
       "  'island',\n",
       "  '.'],\n",
       " ['and',\n",
       "  'a',\n",
       "  'very',\n",
       "  'mean',\n",
       "  'pirate',\n",
       "  'called',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'keeps',\n",
       "  'troubling',\n",
       "  'everyone',\n",
       "  '.'],\n",
       " ['“', 'crocodile', 'bit', 'his', 'one', 'arm', '.'],\n",
       " ['so',\n",
       "  'the',\n",
       "  'captain',\n",
       "  'had',\n",
       "  'to',\n",
       "  'put',\n",
       "  'a',\n",
       "  'hook',\n",
       "  'in',\n",
       "  'its',\n",
       "  'place',\n",
       "  '.'],\n",
       " ['since', 'then', 'he', 'is', 'afraid', 'of', 'crocodiles', '.'],\n",
       " ['and', 'rightly', 'so', '!'],\n",
       " ['if',\n",
       "  'the',\n",
       "  'crocodile',\n",
       "  'ever',\n",
       "  'found',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'it',\n",
       "  'will',\n",
       "  'eat',\n",
       "  'up',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'it',\n",
       "  'couldn',\n",
       "  '’',\n",
       "  't',\n",
       "  'eat',\n",
       "  'last',\n",
       "  'time.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'told',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['soon', 'they', 'landed', 'on', 'the', 'island', '.'],\n",
       " ['and',\n",
       "  'to',\n",
       "  'the',\n",
       "  'surprise',\n",
       "  'of',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  'and',\n",
       "  'michael',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'let',\n",
       "  'them',\n",
       "  'in',\n",
       "  'through',\n",
       "  'a',\n",
       "  'small',\n",
       "  'opening',\n",
       "  'in',\n",
       "  'a',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['inside',\n",
       "  'the',\n",
       "  'tree',\n",
       "  'was',\n",
       "  'a',\n",
       "  'large',\n",
       "  'room',\n",
       "  'with',\n",
       "  'children',\n",
       "  'inside',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['somewhere',\n",
       "  'huddled',\n",
       "  'by',\n",
       "  'the',\n",
       "  'fire',\n",
       "  'in',\n",
       "  'the',\n",
       "  'corner',\n",
       "  'and',\n",
       "  'somewhere',\n",
       "  'playing',\n",
       "  'amongst',\n",
       "  'themselves',\n",
       "  '.'],\n",
       " ['their',\n",
       "  'faces',\n",
       "  'lit',\n",
       "  'up',\n",
       "  'when',\n",
       "  'they',\n",
       "  'saw',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  ',',\n",
       "  'and',\n",
       "  'their',\n",
       "  'guests',\n",
       "  '.'],\n",
       " ['“', 'hello', 'everyone', '.'],\n",
       " ['this', 'is', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
       " ['they',\n",
       "  'will',\n",
       "  'be',\n",
       "  'staying',\n",
       "  'with',\n",
       "  'us',\n",
       "  'from',\n",
       "  'now',\n",
       "  'on.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'introduced',\n",
       "  'them',\n",
       "  'to',\n",
       "  'all',\n",
       "  'children',\n",
       "  '.'],\n",
       " ['children', 'welcomed', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
       " ['a', 'few', 'days', 'passed', '.'],\n",
       " ['and', 'they', 'settled', 'into', 'a', 'routine', '.'],\n",
       " ['wendy',\n",
       "  'would',\n",
       "  'take',\n",
       "  'care',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'in',\n",
       "  'the',\n",
       "  'day',\n",
       "  'and',\n",
       "  'would',\n",
       "  'go',\n",
       "  'out',\n",
       "  'with',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'and',\n",
       "  'her',\n",
       "  'brothers',\n",
       "  'in',\n",
       "  'the',\n",
       "  'evening',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'about',\n",
       "  'the',\n",
       "  'island',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'would',\n",
       "  'cook',\n",
       "  'for',\n",
       "  'them',\n",
       "  'and',\n",
       "  'stitch',\n",
       "  'new',\n",
       "  'clothes',\n",
       "  'for',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'even',\n",
       "  'made',\n",
       "  'a',\n",
       "  'lovely',\n",
       "  'new',\n",
       "  'dress',\n",
       "  'for',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  '.'],\n",
       " ['one',\n",
       "  'evening',\n",
       "  ',',\n",
       "  'as',\n",
       "  'they',\n",
       "  'were',\n",
       "  'out',\n",
       "  'exploring',\n",
       "  'the',\n",
       "  'island',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'warned',\n",
       "  'everyone',\n",
       "  'and',\n",
       "  'said',\n",
       "  ',',\n",
       "  '“',\n",
       "  'hide',\n",
       "  '!'],\n",
       " ['hide', '!'],\n",
       " ['pirates', '!'],\n",
       " ['and',\n",
       "  'they',\n",
       "  'have',\n",
       "  'kidnapped',\n",
       "  'the',\n",
       "  'indian',\n",
       "  'princess',\n",
       "  'tiger',\n",
       "  'lily',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'have',\n",
       "  'kept',\n",
       "  'her',\n",
       "  'there',\n",
       "  ',',\n",
       "  'tied',\n",
       "  'up',\n",
       "  'by',\n",
       "  'the',\n",
       "  'rocks',\n",
       "  ',',\n",
       "  'near',\n",
       "  'the',\n",
       "  'water.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'was',\n",
       "  'afraid',\n",
       "  'and',\n",
       "  'the',\n",
       "  'princess',\n",
       "  'would',\n",
       "  'drown',\n",
       "  ',',\n",
       "  'is',\n",
       "  'she',\n",
       "  'fell',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  '.'],\n",
       " ['so',\n",
       "  ',',\n",
       "  'in',\n",
       "  'a',\n",
       "  'voice',\n",
       "  'that',\n",
       "  'sounded',\n",
       "  'like',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  ',',\n",
       "  'he',\n",
       "  'shouted',\n",
       "  'instructions',\n",
       "  'to',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'who',\n",
       "  'guarded',\n",
       "  'her',\n",
       "  ',',\n",
       "  '“',\n",
       "  'you',\n",
       "  'fools',\n",
       "  '!'],\n",
       " ['let', 'her', 'go', 'at', 'once', '!'],\n",
       " ['do',\n",
       "  'it',\n",
       "  'before',\n",
       "  'i',\n",
       "  'come',\n",
       "  'there',\n",
       "  'or',\n",
       "  'else',\n",
       "  'i',\n",
       "  'will',\n",
       "  'throw',\n",
       "  'each',\n",
       "  'one',\n",
       "  'of',\n",
       "  'you',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water.',\n",
       "  '”',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'got',\n",
       "  'scared',\n",
       "  'and',\n",
       "  'immediately',\n",
       "  'released',\n",
       "  'the',\n",
       "  'princes',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'quickly',\n",
       "  'dived',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  'and',\n",
       "  'swam',\n",
       "  'to',\n",
       "  'the',\n",
       "  'safety',\n",
       "  'of',\n",
       "  'her',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['soon',\n",
       "  'everyone',\n",
       "  'found',\n",
       "  'out',\n",
       "  'how',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'had',\n",
       "  'rescued',\n",
       "  'the',\n",
       "  'princess',\n",
       "  '.'],\n",
       " ['when',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'found',\n",
       "  'out',\n",
       "  'how',\n",
       "  'peter',\n",
       "  'had',\n",
       "  'tricked',\n",
       "  'his',\n",
       "  'men',\n",
       "  'he',\n",
       "  'was',\n",
       "  'furious',\n",
       "  '.'],\n",
       " ['and', 'swore', 'to', 'have', 'his', 'revenge', '.'],\n",
       " ['that',\n",
       "  'night',\n",
       "  'wendy',\n",
       "  'told',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'that',\n",
       "  'she',\n",
       "  'and',\n",
       "  'her',\n",
       "  'brother',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'go',\n",
       "  'back',\n",
       "  'home',\n",
       "  'since',\n",
       "  'they',\n",
       "  'missed',\n",
       "  'their',\n",
       "  'parents',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'said',\n",
       "  'if',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'could',\n",
       "  'also',\n",
       "  'return',\n",
       "  'to',\n",
       "  'her',\n",
       "  'world',\n",
       "  'they',\n",
       "  'could',\n",
       "  'find',\n",
       "  'a',\n",
       "  'nice',\n",
       "  'home',\n",
       "  'for',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['peter', 'pan', 'didn', '’', 't', 'want', 'to', 'leave', 'neverland', '.'],\n",
       " ['but',\n",
       "  'the',\n",
       "  'sake',\n",
       "  'of',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'he',\n",
       "  'agreed',\n",
       "  ',',\n",
       "  'although',\n",
       "  'a',\n",
       "  'bit',\n",
       "  'sadly',\n",
       "  '.'],\n",
       " ['he', 'would', 'miss', 'his', 'friends', 'dearly', '.'],\n",
       " ['the',\n",
       "  'next',\n",
       "  'morning',\n",
       "  'all',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'left',\n",
       "  'with',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'and',\n",
       "  'michael',\n",
       "  '.'],\n",
       " ['but',\n",
       "  'on',\n",
       "  'the',\n",
       "  'way',\n",
       "  ',',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'and',\n",
       "  'his',\n",
       "  'men',\n",
       "  'kidnapped',\n",
       "  'all',\n",
       "  'of',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'tied',\n",
       "  'them',\n",
       "  'and',\n",
       "  'kept',\n",
       "  'them',\n",
       "  'on',\n",
       "  'once',\n",
       "  'of',\n",
       "  'his',\n",
       "  'ships',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'soon',\n",
       "  'as',\n",
       "  'peter',\n",
       "  'found',\n",
       "  'out',\n",
       "  'about',\n",
       "  'it',\n",
       "  'he',\n",
       "  'rushed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'ship',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'swung',\n",
       "  'himself',\n",
       "  'from',\n",
       "  'a',\n",
       "  'tress',\n",
       "  'branch',\n",
       "  'and',\n",
       "  'on',\n",
       "  'to',\n",
       "  'the',\n",
       "  'deck',\n",
       "  'of',\n",
       "  'the',\n",
       "  'ship',\n",
       "  'where',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'were',\n",
       "  'tied',\n",
       "  'up',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'swung',\n",
       "  'his',\n",
       "  'sword',\n",
       "  'bravely',\n",
       "  'and',\n",
       "  'threw',\n",
       "  'over',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'who',\n",
       "  'tried',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'him',\n",
       "  '.'],\n",
       " ['quickly',\n",
       "  'he',\n",
       "  'released',\n",
       "  'everyone',\n",
       "  'from',\n",
       "  'their',\n",
       "  'captor',\n",
       "  '’',\n",
       "  's',\n",
       "  'ties',\n",
       "  '.'],\n",
       " ['wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'michael',\n",
       "  'and',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'helped',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  ',',\n",
       "  'where',\n",
       "  'their',\n",
       "  'friends',\n",
       "  'from',\n",
       "  'the',\n",
       "  'indian',\n",
       "  'camp',\n",
       "  'were',\n",
       "  'ready',\n",
       "  'with',\n",
       "  'smaller',\n",
       "  'boats',\n",
       "  'to',\n",
       "  'take',\n",
       "  'them',\n",
       "  'to',\n",
       "  'safety',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'now',\n",
       "  'went',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['“',\n",
       "  'let',\n",
       "  'us',\n",
       "  'finished',\n",
       "  'this',\n",
       "  'forever',\n",
       "  'mr.',\n",
       "  'hook',\n",
       "  '”',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'challenged',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['“', 'yes', '!'],\n",
       " ['peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'you',\n",
       "  'have',\n",
       "  'caused',\n",
       "  'me',\n",
       "  'enough',\n",
       "  'trouble',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'time',\n",
       "  'that',\n",
       "  'we',\n",
       "  'finished',\n",
       "  'this.',\n",
       "  '”',\n",
       "  'hook',\n",
       "  'replied',\n",
       "  '.'],\n",
       " ['with',\n",
       "  'his',\n",
       "  'sword',\n",
       "  'drawn',\n",
       "  ',',\n",
       "  'he',\n",
       "  'raced',\n",
       "  'towards',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  '.'],\n",
       " ['quick',\n",
       "  'on',\n",
       "  'his',\n",
       "  'feet',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'stepped',\n",
       "  'aside',\n",
       "  'and',\n",
       "  'pushed',\n",
       "  'hook',\n",
       "  'inside',\n",
       "  'the',\n",
       "  'sea',\n",
       "  'where',\n",
       "  'the',\n",
       "  'crocodile',\n",
       "  'was',\n",
       "  'waiting',\n",
       "  'to',\n",
       "  'eat',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['everyone',\n",
       "  'rejoiced',\n",
       "  'as',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'was',\n",
       "  'out',\n",
       "  'of',\n",
       "  'their',\n",
       "  'lives',\n",
       "  'forever',\n",
       "  '.'],\n",
       " ['everybody', 'headed', 'back', 'to', 'london', '.'],\n",
       " ['mr.', 'and', 'mrs', '.'],\n",
       " ['darling',\n",
       "  'was',\n",
       "  'so',\n",
       "  'happy',\n",
       "  'to',\n",
       "  'see',\n",
       "  'their',\n",
       "  'children',\n",
       "  'and',\n",
       "  'they',\n",
       "  'agreed',\n",
       "  'to',\n",
       "  'adopt',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'even',\n",
       "  'asked',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'to',\n",
       "  'come',\n",
       "  'and',\n",
       "  'live',\n",
       "  'with',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['but',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'said',\n",
       "  ',',\n",
       "  'he',\n",
       "  'never',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'up',\n",
       "  ',',\n",
       "  'so',\n",
       "  'he',\n",
       "  'and',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'will',\n",
       "  'go',\n",
       "  'back',\n",
       "  'to',\n",
       "  'neverland',\n",
       "  '.'],\n",
       " ['peter',\n",
       "  'pan',\n",
       "  'promised',\n",
       "  'everyone',\n",
       "  'that',\n",
       "  'he',\n",
       "  'will',\n",
       "  'visit',\n",
       "  'again',\n",
       "  'sometime',\n",
       "  '!'],\n",
       " ['and',\n",
       "  'he',\n",
       "  'flew',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'window',\n",
       "  'with',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'by',\n",
       "  'his',\n",
       "  'side',\n",
       "  '.']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "  \n",
    "sample = open(\"../chap10/data/peter.txt\", \"r\", encoding='UTF8')\n",
    "s = sample.read() \n",
    "  \n",
    "f = s.replace(\"\\n\", \" \")\n",
    "data = [] \n",
    "  \n",
    "for i in sent_tokenize(f):\n",
    "    temp = [] \n",
    "    for j in word_tokenize(i):\n",
    "        temp.append(j.lower())\n",
    "    data.append(temp) \n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8789851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcbd3aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' wendy' - CBOW :  1.0\n"
     ]
    }
   ],
   "source": [
    "model1 = gensim.models.Word2Vec(data, min_count = 1,  \n",
    "                              vector_size = 100, window = 5, sg=0)\n",
    "print(\"Cosine similarity between 'peter' \" +\n",
    "                 \"wendy' - CBOW : \", \n",
    "      model1.wv.similarity('wendy', 'wendy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f6eac9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' hook' - CBOW :  0.027709894\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarity between 'peter' \" +\n",
    "                 \"hook' - CBOW : \", \n",
    "      model1.wv.similarity('peter', 'hook')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08e2366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fb8edd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' wendy' - Skip Gram :  0.40088683\n"
     ]
    }
   ],
   "source": [
    "model2 = gensim.models.Word2Vec(data, min_count = 1, vector_size = 100, \n",
    "                                             window = 5, sg = 1)\n",
    "print(\"Cosine similarity between 'peter' \" +\n",
    "          \"wendy' - Skip Gram : \", \n",
    "    model2.wv.similarity('peter', 'wendy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8128bcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' hook' - Skip Gram :  0.52016735\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarity between 'peter' \" +\n",
    "            \"hook' - Skip Gram : \", \n",
    "      model2.wv.similarity('peter', 'hook')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f6e37fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20a1b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import FastText\n",
    "\n",
    "model = FastText('../chap10/data/peter.txt', vector_size=4, window=3, min_count=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "216300d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45924556\n"
     ]
    }
   ],
   "source": [
    "sim_score = model.wv.similarity('peter', 'wendy')\n",
    "print(sim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8afd9c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043825187\n"
     ]
    }
   ],
   "source": [
    "sim_score = model.wv.similarity('peter', 'hook')\n",
    "print(sim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4543f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_kr = KeyedVectors.load_word2vec_format('../chap10/data/wiki.ko.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5fb5c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 노력함, Similarity: 0.80\n",
      "Word: 노력중, Similarity: 0.75\n",
      "Word: 노력만, Similarity: 0.72\n",
      "Word: 노력과, Similarity: 0.71\n",
      "Word: 노력의, Similarity: 0.69\n",
      "Word: 노력가, Similarity: 0.69\n",
      "Word: 노력이나, Similarity: 0.69\n",
      "Word: 노력없이, Similarity: 0.68\n",
      "Word: 노력맨, Similarity: 0.68\n",
      "Word: 노력보다는, Similarity: 0.68\n"
     ]
    }
   ],
   "source": [
    "find_similar_to = '노력'\n",
    "\n",
    "for similar_word in model_kr.similar_by_word(find_similar_to):\n",
    "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
    "        similar_word[0], similar_word[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "346acbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('초식동물', 0.7804122567176819), ('거대동물', 0.7547270655632019), ('육식동물의', 0.7547166347503662), ('유두동물', 0.753511369228363), ('반추동물', 0.7470757961273193), ('독동물', 0.7466291785240173), ('육상동물', 0.746031641960144), ('유즐동물', 0.7450903654098511), ('극피동물', 0.7449344396591187), ('복모동물', 0.742434561252594)]\n"
     ]
    }
   ],
   "source": [
    "similarities = model_kr.most_similar(positive=['동물', '육식동물'], negative=['사람'])\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "376e7c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.1.4 횟수/예측기반 임베딩\n",
    "#GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5752236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = datapath('../chap10/data/glove.6B.100d.txt')\n",
    "word2vec_glove_file = get_tmpfile(\"glove.6B.100d.word2vec.txt\")\n",
    "glove2word2vec(glove_file, word2vec_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3db496ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('legislation', 0.8072139620780945),\n",
       " ('proposal', 0.730686366558075),\n",
       " ('senate', 0.7142541408538818),\n",
       " ('bills', 0.704440176486969),\n",
       " ('measure', 0.6958035230636597),\n",
       " ('passed', 0.690624475479126),\n",
       " ('amendment', 0.6846879720687866),\n",
       " ('provision', 0.6845567226409912),\n",
       " ('plan', 0.6816462874412537),\n",
       " ('clinton', 0.6663140058517456)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
    "model.most_similar('bill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57d14331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('peach', 0.688809871673584),\n",
       " ('mango', 0.683819055557251),\n",
       " ('plum', 0.6684104204177856),\n",
       " ('berry', 0.6590359210968018),\n",
       " ('grove', 0.658155083656311),\n",
       " ('blossom', 0.6503506302833557),\n",
       " ('raspberry', 0.6477391719818115),\n",
       " ('strawberry', 0.6442098021507263),\n",
       " ('pine', 0.6390928626060486),\n",
       " ('almond', 0.6379212737083435)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('cherry') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c609124b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('str94', 0.5899437069892883),\n",
       " ('http://www.ecb.int', 0.5723982453346252),\n",
       " ('rw95', 0.5641242265701294),\n",
       " ('js04bb', 0.5608091354370117),\n",
       " ('http://www.opel.com', 0.5586654543876648),\n",
       " ('obloquy', 0.5543686151504517),\n",
       " ('backstrap', 0.5506628155708313),\n",
       " ('disinfects', 0.5451074838638306),\n",
       " ('shepherdesses', 0.5444405674934387),\n",
       " ('hereros', 0.5441645383834839)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(negative='cherry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21c9f828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen: 0.7699\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72881522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'champagne'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analogy(x1, x2, y1):\n",
    "    result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
    "    return result[0][0]\n",
    "analogy('australia', 'beer', 'france')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a8a76cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'longest'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('tall', 'tallest', 'long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "820bf3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cereal\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d9c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.2 Transformer attention\n",
    "#10.2.1 Seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae5b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4841b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  \n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ebe3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(df, lang):\n",
    "    sentence = df[lang].str.lower()\n",
    "    sentence = sentence.str.replace('[^A-Za-z\\s]+', '')\n",
    "    sentence = sentence.str.normalize('NFD')\n",
    "    sentence = sentence.str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    return sentence\n",
    "\n",
    "def read_sentence(df, lang1, lang2):\n",
    "    sentence1 = normalizeString(df, lang1)\n",
    "    sentence2 = normalizeString(df, lang2)\n",
    "    return sentence1, sentence2\n",
    "\n",
    "def read_file(loc, lang1, lang2):\n",
    "    df = pd.read_csv(loc, delimiter='\\t', header=None, names=[lang1, lang2])\n",
    "    return df\n",
    "\n",
    "def process_data(lang1,lang2):\n",
    "    df = read_file('../chap10/data/%s-%s.txt' % (lang1, lang2), lang1, lang2)\n",
    "    sentence1, sentence2 = read_sentence(df, lang1, lang2)\n",
    "\n",
    "    input_lang = Lang()\n",
    "    output_lang = Lang()\n",
    "    pairs = []\n",
    "    for i in range(len(df)):\n",
    "        if len(sentence1[i].split(' ')) < MAX_LENGTH and len(sentence2[i].split(' ')) < MAX_LENGTH:\n",
    "            full = [sentence1[i], sentence2[i]]\n",
    "            input_lang.addSentence(sentence1[i])\n",
    "            output_lang.addSentence(sentence2[i])\n",
    "            pairs.append(full)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0c3e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(input_lang, output_lang, pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5cda608",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, embbed_dim, num_layers):\n",
    "        super(Encoder, self).__init__()       \n",
    "        self.input_dim = input_dim\n",
    "        self.embbed_dim = embbed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_dim, self.embbed_dim)\n",
    "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
    "              \n",
    "    def forward(self, src):      \n",
    "        embedded = self.embedding(src).view(1,1,-1)\n",
    "        outputs, hidden = self.gru(embedded)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8c263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, embbed_dim, num_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embbed_dim = embbed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, self.embbed_dim)\n",
    "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
    "        self.out = nn.Linear(self.hidden_dim, output_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "      \n",
    "    def forward(self, input, hidden):\n",
    "        input = input.view(1, -1)\n",
    "        embedded = F.relu(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded, hidden)       \n",
    "        prediction = self.softmax(self.out(output[0]))      \n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e32442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, MAX_LENGTH=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "      \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "     \n",
    "    def forward(self, input_lang, output_lang, teacher_forcing_ratio=0.5):\n",
    "\n",
    "        input_length = input_lang.size(0)\n",
    "        batch_size = output_lang.shape[1] \n",
    "        target_length = output_lang.shape[0]\n",
    "        vocab_size = self.decoder.output_dim      \n",
    "        outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
    "\n",
    "        for i in range(input_length):\n",
    "            encoder_output, encoder_hidden = self.encoder(input_lang[i])\n",
    "\n",
    "        decoder_hidden = encoder_hidden.to(device)  \n",
    "        decoder_input = torch.tensor([SOS_token], device=device)  \n",
    "\n",
    "        for t in range(target_length):   \n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "            outputs[t] = decoder_output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            input = (output_lang[t] if teacher_force else topi)\n",
    "            if(teacher_force == False and input.item() == EOS_token):\n",
    "                break\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93d4ebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def Model(model, input_tensor, target_tensor, model_optimizer, criterion):\n",
    "    model_optimizer.zero_grad()\n",
    "    input_length = input_tensor.size(0)\n",
    "    loss = 0\n",
    "    epoch_loss = 0\n",
    "    output = model(input_tensor, target_tensor)\n",
    "    num_iter = output.size(0)\n",
    "\n",
    "    for ot in range(num_iter):\n",
    "        loss += criterion(output[ot], target_tensor[ot])\n",
    "\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "    epoch_loss = loss.item() / num_iter\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9768b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, input_lang, output_lang, pairs, num_iteration=20000):\n",
    "    model.train()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = nn.NLLLoss()\n",
    "    total_loss_iterations = 0\n",
    "\n",
    "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs))\n",
    "                      for i in range(num_iteration)]\n",
    "  \n",
    "    for iter in range(1, num_iteration+1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        loss = Model(model, input_tensor, target_tensor, optimizer, criterion)\n",
    "        total_loss_iterations += loss\n",
    "\n",
    "        if iter % 5000 == 0:\n",
    "            average_loss= total_loss_iterations / 5000\n",
    "            total_loss_iterations = 0\n",
    "            print('%d %.4f' % (iter, average_loss))\n",
    "          \n",
    "    torch.save(model.state_dict(), '../chap10/data/mytraining.pt')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bd2079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, input_lang, output_lang, sentences, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentences[0])\n",
    "        output_tensor = tensorFromSentence(output_lang, sentences[1])  \n",
    "        decoded_words = []  \n",
    "        output = model(input_tensor, output_tensor)\n",
    "  \n",
    "        for ot in range(output.size(0)):\n",
    "            topv, topi = output[ot].topk(1)\n",
    "\n",
    "            if topi[0].item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi[0].item()])\n",
    "    return decoded_words\n",
    "\n",
    "def evaluateRandomly(model, input_lang, output_lang, pairs, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('input {}'.format(pair[0]))\n",
    "        print('output {}'.format(pair[1]))\n",
    "        output_words = evaluate(model, input_lang, output_lang, pair)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('predicted {}'.format(output_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6814115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-833b8db6190e>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  sentence = sentence.str.replace('[^A-Za-z\\s]+', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random sentence ['how could i forget', 'comment pourraisje oublier ']\n",
      "Input : 13366 Output : 25937\n",
      "Encoder(\n",
      "  (embedding): Embedding(13366, 256)\n",
      "  (gru): GRU(256, 512)\n",
      ")\n",
      "Decoder(\n",
      "  (embedding): Embedding(25937, 256)\n",
      "  (gru): GRU(256, 512)\n",
      "  (out): Linear(in_features=512, out_features=25937, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n",
      "5000 4.8727\n",
      "10000 4.6251\n",
      "15000 4.5742\n",
      "20000 4.5565\n",
      "25000 4.4561\n",
      "30000 4.5035\n",
      "35000 4.5094\n",
      "40000 4.4538\n",
      "45000 4.4900\n",
      "50000 4.4364\n",
      "55000 4.4599\n",
      "60000 4.4883\n",
      "65000 4.4649\n",
      "70000 4.4384\n",
      "75000 4.4197\n"
     ]
    }
   ],
   "source": [
    "lang1 = 'eng'\n",
    "lang2 = 'fra'\n",
    "input_lang, output_lang, pairs = process_data(lang1, lang2)\n",
    "\n",
    "randomize = random.choice(pairs)\n",
    "print('random sentence {}'.format(randomize))\n",
    "\n",
    "input_size = input_lang.n_words\n",
    "output_size = output_lang.n_words\n",
    "print('Input : {} Output : {}'.format(input_size, output_size))\n",
    "\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "num_iteration = 75000\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
    "decoder = Decoder(output_size, hidden_size, embed_size, num_layers)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    " \n",
    "print(encoder)\n",
    "print(decoder)\n",
    "\n",
    "model = trainModel(model, input_lang, output_lang, pairs, num_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa2807a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input what would we do instead\n",
      "output que ferionsnous  la place \n",
      "predicted je ne pas  <EOS>\n",
      "input he is eight\n",
      "output il a huit ans\n",
      "predicted je ne pas  <EOS>\n",
      "input what time is your plane due to take off\n",
      "output  quelle heure votre avion doit dcoller\n",
      "predicted je ne pas  <EOS>\n",
      "input you must take advantage of the opportunity\n",
      "output tu dois saisir cette occasion\n",
      "predicted je ne pas  <EOS>\n",
      "input he is always finding fault with other people\n",
      "output il trouve toujours  redire aux autres\n",
      "predicted je ne pas  <EOS>\n",
      "input you have many books\n",
      "output tu as de nombreux livres\n",
      "predicted je ne pas  <EOS>\n",
      "input i have an appointment with my lawyer today\n",
      "output jai rendezvous avec mon avocat aujourdhui\n",
      "predicted je ne pas  <EOS>\n",
      "input he wiped his nose on his sleeve\n",
      "output il essuya la morve sur sa manche\n",
      "predicted je ne pas  <EOS>\n",
      "input youve been very kind to me\n",
      "output tu as t trs gentille avec moi\n",
      "predicted je ne pas  <EOS>\n",
      "input at that time tom wasnt very happy\n",
      "output  cette poque thomas ntait pas vraiment heureux\n",
      "predicted je ne pas  <EOS>\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(model, input_lang, output_lang, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6032888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bb7ef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  \n",
    "    plot_loss_total = 0  \n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        loss = Model(model, input_tensor, target_tensor, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % 5000 == 0:\n",
    "            print_loss_avg = print_loss_total / 5000\n",
    "            print_loss_total = 0\n",
    "            print('%d,  %.4f' % (iter, print_loss_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6df879d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (embedding): Embedding(13366, 256)\n",
      "  (gru): GRU(256, 512)\n",
      ")\n",
      "AttnDecoderRNN(\n",
      "  (embedding): Embedding(25937, 512)\n",
      "  (attn): Linear(in_features=1024, out_features=20, bias=True)\n",
      "  (attn_combine): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (gru): GRU(512, 512)\n",
      "  (out): Linear(in_features=512, out_features=25937, bias=True)\n",
      ")\n",
      "5000,  4.7177\n",
      "10000,  4.6950\n",
      "15000,  4.7199\n",
      "20000,  4.7055\n",
      "25000,  4.6900\n",
      "30000,  4.6944\n",
      "35000,  4.7256\n",
      "40000,  4.6759\n",
      "45000,  4.7069\n",
      "50000,  4.7136\n",
      "55000,  4.6948\n",
      "60000,  4.6980\n",
      "65000,  4.6819\n",
      "70000,  4.7009\n",
      "75000,  4.6895\n"
     ]
    }
   ],
   "source": [
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "input_size = input_lang.n_words\n",
    "output_size = output_lang.n_words\n",
    "\n",
    "encoder1 = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_size, dropout_p=0.1).to(device)\n",
    "\n",
    "print(encoder1)\n",
    "print(attn_decoder1)\n",
    "\n",
    "attn_model = trainIters(encoder1, attn_decoder1, 75000, print_every=5000, plot_every=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "201fd8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.2.1 Bert\n",
    "#!pip install transformers\n",
    "#!pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20b91e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from pytorch_transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa39b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../chap10/data/training.txt', sep='\\t')\n",
    "valid_df = pd.read_csv('../chap10/data/validing.txt', sep='\\t')\n",
    "test_df = pd.read_csv('../chap10/data/testing.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e620c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=0.1, random_state=500)\n",
    "valid_df = valid_df.sample(frac=0.1, random_state=500)\n",
    "test_df = test_df.sample(frac=0.1, random_state=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8506022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx, 1]\n",
    "        label = self.df.iloc[idx, 2]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97277c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Datasets(train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "valid_dataset = Datasets(valid_df)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "test_dataset = Datasets(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "106307e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 231508/231508 [00:01<00:00, 224129.83B/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 433/433 [00:00<00:00, 86850.64B/s]\n",
      "100%|████████████████████████████████████████████████████████████████| 440473133/440473133 [04:23<00:00, 1670428.30B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c0f5fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(save_path, model, valid_loss):\n",
    "    if save_path == None:\n",
    "        return    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_checkpoint(load_path, model):    \n",
    "    if load_path==None:\n",
    "        return    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "    if save_path == None:\n",
    "        return    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_metrics(load_path):\n",
    "    if load_path==None:\n",
    "        return    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0871e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.BCELoss(),\n",
    "          num_epochs = 5,\n",
    "          eval_every = len(train_loader) // 2,\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    total_correct = 0.0\n",
    "    total_len = 0.0\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for text, label in train_loader:\n",
    "            optimizer.zero_grad()        \n",
    "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "            padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
    "        \n",
    "            sample = torch.tensor(padded_list)\n",
    "            sample, label = sample.to(device), label.to(device)\n",
    "            labels = torch.tensor(label)\n",
    "            outputs = model(sample, labels=labels)\n",
    "            loss, logits = outputs\n",
    "\n",
    "            pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "            correct = pred.eq(labels)\n",
    "            total_correct += correct.sum().item()\n",
    "            total_len += len(labels)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()        \n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "                    for text, label in valid_loader:\n",
    "                        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "                        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]        \n",
    "                        sample = torch.tensor(padded_list)\n",
    "                        sample, label = sample.to(device), label.to(device)\n",
    "                        labels = torch.tensor(label)\n",
    "                        outputs = model(sample, labels=labels)\n",
    "                        loss, logits = outputs                        \n",
    "                        valid_running_loss += loss.item()\n",
    "\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint('../chap10/data/model.pt', model, best_valid_loss)\n",
    "                    save_metrics('../chap10/data/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    \n",
    "    save_metrics('../chap10/data/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('훈련 종료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f69dac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a31c36cee61b>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(label)\n",
      "<ipython-input-9-a31c36cee61b>:37: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred = torch.argmax(F.softmax(logits), dim=1)\n",
      "<ipython-input-9-a31c36cee61b>:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [510/5100], Train Loss: 0.7124, Valid Loss: 0.6968\n",
      "Model saved to ==> e:/torch/chap10/data/model.pt\n",
      "Model saved to ==> e:/torch/chap10/data/metrics.pt\n",
      "Epoch [1/5], Step [1020/5100], Train Loss: 0.7127, Valid Loss: 0.6970\n",
      "Epoch [2/5], Step [1530/5100], Train Loss: 0.7067, Valid Loss: 0.6943\n",
      "Model saved to ==> e:/torch/chap10/data/model.pt\n",
      "Model saved to ==> e:/torch/chap10/data/metrics.pt\n",
      "Epoch [2/5], Step [2040/5100], Train Loss: 0.7023, Valid Loss: 0.7232\n",
      "Epoch [3/5], Step [2550/5100], Train Loss: 0.7059, Valid Loss: 0.6932\n",
      "Model saved to ==> e:/torch/chap10/data/model.pt\n",
      "Model saved to ==> e:/torch/chap10/data/metrics.pt\n",
      "Epoch [3/5], Step [3060/5100], Train Loss: 0.6999, Valid Loss: 0.6927\n",
      "Model saved to ==> e:/torch/chap10/data/model.pt\n",
      "Model saved to ==> e:/torch/chap10/data/metrics.pt\n",
      "Epoch [4/5], Step [3570/5100], Train Loss: 0.7023, Valid Loss: 0.6943\n",
      "Epoch [4/5], Step [4080/5100], Train Loss: 0.6990, Valid Loss: 0.6928\n",
      "Epoch [5/5], Step [4590/5100], Train Loss: 0.7005, Valid Loss: 0.6928\n",
      "Epoch [5/5], Step [5100/5100], Train Loss: 0.6984, Valid Loss: 0.6968\n",
      "Model saved to ==> e:/torch/chap10/data/metrics.pt\n",
      "훈련 종료!\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "train(model=model, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2abbb6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== e:/torch/chap10/data/metrics.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics('../chap10/data/metrics.pt')\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cb68692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for text, label in test_loader:\n",
    "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "            padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
    "        \n",
    "            sample = torch.tensor(padded_list)\n",
    "            sample, label = sample.to(device), label.to(device)\n",
    "            labels = torch.tensor(label)\n",
    "            output = model(sample, labels=labels)\n",
    "            \n",
    "            _, output = output\n",
    "            y_pred.extend(torch.argmax(output, 1).tolist())\n",
    "            y_true.extend(labels.tolist())\n",
    "                    \n",
    "    print('Classification 결과:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "    \n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "    ax.xaxis.set_ticklabels(['0', '1'])\n",
    "    ax.yaxis.set_ticklabels(['0', '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97dfe435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== e:/torch/chap10/data/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-f9df6714cef0>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification 결과:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5091    1.0000    0.6747       558\n",
      "           0     0.0000    0.0000    0.0000       538\n",
      "\n",
      "    accuracy                         0.5091      1096\n",
      "   macro avg     0.2546    0.5000    0.3374      1096\n",
      "weighted avg     0.2592    0.5091    0.3435      1096\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = model.to(device)\n",
    "load_checkpoint('../chap10/data/model.pt', best_model)\n",
    "evaluate(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64b382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.3 한국어 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e14558a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534b48b6df5241d8ab12ea1ef1e337ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/972k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b104277e084ad6aa3d377ae717da8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c34d422a47418c8f87ba1256dd903a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.87M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed24fd0ad927464d8475adb81d5434ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfe6d8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '나는', '파', '##이', '##토', '##치를', '이', '##용한', '딥', '##러', '##닝', '##을', '학', '##습', '##중', '##이다', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text = \"나는 파이토치를 이용한 딥러닝을 학습중이다.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3740f31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "과             8,898\n",
      "##수          15,891\n",
      "##원에         108,280\n",
      "사             9,405\n",
      "##과          11,882\n",
      "##가          11,287\n",
      "많             9,249\n",
      "##았다         27,303\n",
      ".               119\n",
      "친             9,781\n",
      "##구          17,196\n",
      "##가          11,287\n",
      "나             8,982\n",
      "##에게         26,212\n",
      "사             9,405\n",
      "##과          11,882\n",
      "##했다         12,490\n",
      ".               119\n",
      "백             9,331\n",
      "##설          31,928\n",
      "##공          28,000\n",
      "##주는         100,633\n",
      "독             9,088\n",
      "##이          10,739\n",
      "든             9,115\n",
      "사             9,405\n",
      "##과          11,882\n",
      "##를          11,513\n",
      "먹             9,266\n",
      "##었다         17,706\n",
      ".               119\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "text = \"과수원에 사과가 많았다.\" \\\n",
    "       \"친구가 나에게 사과했다.\"\\\n",
    "       \"백설공주는 독이 든 사과를 먹었다.\"\n",
    "\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da9f047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "segments_ids = [1] * len(tokenized_text)\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b9a81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2637806e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75c2ed4c0e745169544118ef8889ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-multilingual-cased',\n",
    "                                  output_hidden_states = True,)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ba79d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e61815e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "계층 수: 13   (initial embeddings + 12 BERT layers)\n",
      "배치 수: 1\n",
      "토큰 수: 33\n",
      "은닉층 유닛 수: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"계층 수:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"배치 수:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"토큰 수:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"은닉층 유닛 수:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c79e83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "은닉 상태의 유형:  <class 'tuple'>\n",
      "각 계층에서의 텐서 형태:  torch.Size([1, 33, 768])\n"
     ]
    }
   ],
   "source": [
    "print('은닉 상태의 유형: ', type(hidden_states))\n",
    "print('각 계층에서의 텐서 형태: ', hidden_states[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9633fe69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1, 33, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d777453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 33, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa6a4d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 13, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b2f7874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태는: 33 x 3072\n"
     ]
    }
   ],
   "source": [
    "token_vecs_cat = []\n",
    "for token in token_embeddings:\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "print ('형태는: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7621bc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태는: 33 x 768\n"
     ]
    }
   ],
   "source": [
    "token_vecs_sum = []\n",
    "for token in token_embeddings:\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "print ('형태는: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a14ae7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 임베딩 벡터의 형태: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "token_vecs = hidden_states[-2][0]\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "print (\"최종 임베딩 벡터의 형태:\", sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0b581d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 과\n",
      "2 ##수\n",
      "3 ##원에\n",
      "4 사\n",
      "5 ##과\n",
      "6 ##가\n",
      "7 많\n",
      "8 ##았다\n",
      "9 .\n",
      "10 친\n",
      "11 ##구\n",
      "12 ##가\n",
      "13 나\n",
      "14 ##에게\n",
      "15 사\n",
      "16 ##과\n",
      "17 ##했다\n",
      "18 .\n",
      "19 백\n",
      "20 ##설\n",
      "21 ##공\n",
      "22 ##주는\n",
      "23 독\n",
      "24 ##이\n",
      "25 든\n",
      "26 사\n",
      "27 ##과\n",
      "28 ##를\n",
      "29 먹\n",
      "30 ##었다\n",
      "31 .\n",
      "32 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokenized_text):\n",
    "    print (i, token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb56c9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사과가 많았다 tensor([-0.5844, -4.0836,  0.4906,  0.8915, -1.8054])\n",
      "나에게 사과했다 tensor([-0.8631, -3.4047, -0.7351,  0.9805, -2.6700])\n",
      "사과를 먹었다 tensor([ 0.6756, -0.3618,  0.0586,  2.2050, -2.4193])\n"
     ]
    }
   ],
   "source": [
    "print(\"사과가 많았다\", str(token_vecs_sum[6][:5]))\n",
    "print(\"나에게 사과했다\", str(token_vecs_sum[10][:5]))\n",
    "print(\"사과를 먹었다\", str(token_vecs_sum[19][:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbc2e65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*유사한* 의미에 대한 벡터 유사성:  0.86\n",
      "*다른* 의미에 대한 벡터 유사성:  0.91\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "diff_apple = 1 - cosine(token_vecs_sum[5], token_vecs_sum[27])\n",
    "same_apple = 1 - cosine(token_vecs_sum[5], token_vecs_sum[16])\n",
    "print('*유사한* 의미에 대한 벡터 유사성:  %.2f' % same_apple)\n",
    "print('*다른* 의미에 대한 벡터 유사성:  %.2f' % diff_apple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c53aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
